{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMLD Workshop Notebook 3\n",
    "\n",
    "In this notebook, you will combine what you learned in notebooks 1 and 2 to train a federated machine learning task.\n",
    "\n",
    "## ðŸŽ¯ OBJECTIVE\n",
    "\n",
    "Train the same machine learning model collaboratively across multiple institutions using federated learning, without transferring raw patient data outside local environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(182, 255, 18, 0.15); border-left: 5px solid #B6FF12; padding: 15px; margin: 10px 0;\">\n",
    "<h3> Real-world context</h3>\n",
    "<p>In healthcare, data is often legally and ethically constrained to remain within institutional or national boundaries. As a result, pooling datasets into a single central location for AI training is frequently infeasible. Yet, developing robust and generalizable models requires access to diverse populations and larger sample sizes than any single institution can typically provide.\n",
    "\n",
    "Federated learning addresses this tension by allowing each institution to train a model locally and share only model updates rather than raw data. In practice, this requires more than just algorithms: it depends on secure execution environments, identity management, authorization workflows, and auditability across all participating sites.\n",
    "\n",
    "In this setup, CHORUS provides the secure processing environment and governance controls at each hospital node, while Tune Insight coordinates the federated training process across institutions. Together, they make cross-institution AI development operationally feasible while respecting data sovereignty and regulatory constraints.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ IMPLEMENTATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "from tuneinsight import Diapason, models\n",
    "from tuneinsight.computations import HybridFL\n",
    "import tuneinsight.utils.time_tools as time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amld_setup import *\n",
    "\n",
    "# TODO: Please update the credentials below with those provided to you.\n",
    "%env TI_USERNAME=amld-workshopX@tuneinsight.com\n",
    "%env TI_PASSWORD=AMLD_workshop_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Diapason.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.healthcheck()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and share the project\n",
    "\n",
    "Projects are the main unit of collaboration in Tune Insight projects. In a project, you will define the computation to run in a federated setting, and set the datasource used by your instance. Other participants will also choose the data used by their instance. Once everything is set up, the federated analysis can be run using data from all instances, without centralizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = f\"project-3-{uuid.uuid4()}\"\n",
    "\n",
    "project = client.new_project(name=PROJECT_NAME, clear_if_exists=True)\n",
    "project.share()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/data_0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play around with the data if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"split\"] = \"train\"\n",
    "df.loc[df.sample(frac=0.2, random_state=42).index, \"split\"] = \"val\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data to the instance and set it on the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = client.new_datasource(dataframe=df, name=f\"patient_data_{uuid.uuid4()}\", clear_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_datasource(datasource)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Definition\n",
    "\n",
    "In this notebook, we will define a machine learning task with the `ti-models` library, similar to what you did in notebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from ti_models.models.ti_model import TIModel\n",
    "from ti_models.preprocessing.preprocessing import Preprocessing, InputType\n",
    "from ti_models.preprocessing.datasets.csv_dataset import CSVDataset\n",
    "from ti_models.trainer.ti_trainer import TITrainer\n",
    "from ti_models.trainer.ti_loss import TILoss\n",
    "from ti_models.trainer.ti_optimizer import TIOptimizer, OptimizerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model architecture in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 4\n",
    "N_CLASSES = 2\n",
    "\n",
    "torch_model = nn.Sequential(\n",
    "    nn.BatchNorm1d(INPUT_DIM, affine=False, track_running_stats=True),\n",
    "    nn.Linear(INPUT_DIM, N_CLASSES),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the `TIModel` wrapper that adds constraints to data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing(input_type=InputType.TABULAR, input_shape=(INPUT_DIM,))\n",
    "\n",
    "model = TIModel(\n",
    "    name=\"LogisticRegression\",\n",
    "    description=\"Logistic Regression classifier for prostate cancer detection task\",\n",
    "    n_classes=N_CLASSES,\n",
    "    torch_model=torch_model,\n",
    "    preprocessing=preprocessing,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the federated trainer `TITrainer` that specifies loss, optimizer and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "loss = TILoss(loss_func=nn.CrossEntropyLoss())\n",
    "\n",
    "optimizer = TIOptimizer(\n",
    "    optimizer_type=OptimizerType.SECURE_SGD,\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM\n",
    ")\n",
    "\n",
    "trainer = TITrainer(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with a preliminary local training on your dataset\n",
    "\n",
    "Create the datasets for local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"split\"] == \"train\"].drop(columns=[\"split\"])\n",
    "val_df = df[df[\"split\"] == \"val\"].drop(columns=[\"split\"])\n",
    "\n",
    "train_dataset = CSVDataset(df = train_df)\n",
    "val_dataset = CSVDataset(df = val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the trainer to avoid modifications on the federated trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_trainer = TITrainer.unmarshal_binary(trainer.marshal_binary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for 3 epochs using the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_trainer.train(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    epochs=3,\n",
    "    eval_after_epoch=True,\n",
    "    logging_frequency=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy = round(local_trainer.history.get_curve(\"accuracy\")[-1][2], 4)\n",
    "print(\"Local accuracy:\", local_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the parameters for Federated Learning\n",
    "\n",
    "We do 3 collective rounds of 1 local epoch each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = models.HybridFLGenericParams(\n",
    "    fl_rounds=3,\n",
    "    num_workers=2,\n",
    "    strategy = models.aggregation_strategy.AggregationStrategy.CONSTANT\n",
    ")\n",
    "\n",
    "ml_params = models.HybridFLMachineLearningParams(\n",
    "    local_epochs=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    momentum=MOMENTUM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the computation (Federated Learning) on the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_fl = HybridFL(\n",
    "    project=project,\n",
    "    task_id = \"logreg\",\n",
    "    trainer=trainer,\n",
    "    params=params,\n",
    "    spec_params= ml_params,\n",
    ")\n",
    "hybrid_fl.max_timeout = 300 * 60 * time.SECOND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clients authorize the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.request_authorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can get a quick summary of the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.display_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.display_datasources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training\n",
    "\n",
    "This will run a federated learning on the network of four instances (three contributing, and a coordinating root node).\n",
    "\n",
    "Note: you might experience the following error\n",
    "\n",
    "> `InternalError: error happened internally: unexpected error: please contact the instance's administrator`\n",
    "\n",
    "if that is the case, please call one of the organizers for assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_fl.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the result history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = project.fetch_results()[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_fl.display_results(results.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "federated_accuracy = round(json.loads(results.history.metrics[-1])[\"accuracy\"][-1][1], 4)\n",
    "print(\"Local accuracy:\", local_accuracy)\n",
    "print(\"Federated accuracy:\", federated_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
