{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMLD Workshop Notebook 4\n",
    "\n",
    "In this notebook, you will combine what you learned in notebook 3 to train a federated learning task with advanced data protection using gradient clipping and differential privacy.\n",
    "\n",
    "## ðŸŽ¯ OBJECTIVE\n",
    "\n",
    "Train the same machine learning model collaboratively across multiple institutions using federated learning, without transferring raw patient data outside local environments. Additionally, incorporate gradient clipping during local training and inject calibrated differential privacy noise into the exchanged model updates. This bounds the sensitivity of each clientâ€™s contribution and mitigates risks such as membership inference, model inversion, and reconstruction attacks, thereby providing formal privacy guarantees for the local training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(182, 255, 18, 0.15); border-left: 5px solid #B6FF12; padding: 15px; margin: 10px 0;\">\n",
    "<h3> Real-world context</h3>\n",
    "<p>In healthcare, data is often legally and ethically constrained to remain within institutional or national boundaries. As a result, pooling datasets into a single central location for AI training is frequently infeasible. Yet, developing robust and generalizable models requires access to diverse populations and larger sample sizes than any single institution can typically provide.\n",
    "\n",
    "Federated learning addresses this tension by allowing each institution to train a model locally and share only model updates rather than raw data. In practice, this requires more than just algorithms: it depends on secure execution environments, identity management, authorization workflows, and auditability across all participating sites.\n",
    "\n",
    "In this setup, CHORUS provides the secure processing environment and governance controls at each hospital node, while Tune Insight coordinates the federated training process across institutions. Together, they make cross-institution AI development operationally feasible while respecting data sovereignty and regulatory constraints.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "from tuneinsight import Diapason, models\n",
    "from tuneinsight.computations import HybridFL\n",
    "import tuneinsight.utils.time_tools as time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amld_setup import *\n",
    "\n",
    "# TODO: Please update the credentials below with those provided to you.\n",
    "%env TI_USERNAME=amld-workshopX@tuneinsight.com\n",
    "%env TI_PASSWORD=AMLD_workshop_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Diapason.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.healthcheck()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and share the project\n",
    "\n",
    "Projects are the main unit of collaboration in Tune Insight projects. In a project, you will define the computation to run in a federated setting, and set the datasource used by your instance. Other participants will also choose the data used by their instance. Once everything is set up, the federated analysis can be run using data from all instances, without centralizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = f\"project-4-{uuid.uuid4()}\"\n",
    "\n",
    "project = client.new_project(name=PROJECT_NAME, clear_if_exists=True)\n",
    "project.share()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/data_0.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play around with the data if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"split\"] = \"train\"\n",
    "df.loc[df.sample(frac=0.2, random_state=42).index, \"split\"] = \"val\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data to the instance and set it on the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = client.new_datasource(dataframe=df, name=f\"patient_data_{uuid.uuid4()}\", clear_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_datasource(datasource)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Definition\n",
    "\n",
    "In this notebook, we will define a machine learning task with the `ti-models` library, similar to what you did in notebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from ti_models.models.ti_model import TIModel\n",
    "from ti_models.preprocessing.preprocessing import Preprocessing, InputType\n",
    "from ti_models.preprocessing.datasets.csv_dataset import CSVDataset\n",
    "from ti_models.trainer.ti_trainer import TITrainer\n",
    "from ti_models.trainer.ti_loss import TILoss\n",
    "from ti_models.trainer.ti_optimizer import TIOptimizer, OptimizerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model architecture in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 4\n",
    "N_CLASSES = 2\n",
    "\n",
    "torch_model = nn.Sequential(\n",
    "    nn.BatchNorm1d(INPUT_DIM, affine=False, track_running_stats=True),\n",
    "    nn.Linear(INPUT_DIM, N_CLASSES),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the `TIModel` wrapper that adds constraints to data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing(input_type=InputType.TABULAR, input_shape=(INPUT_DIM,))\n",
    "\n",
    "model = TIModel(\n",
    "    name=\"LogisticRegression\",\n",
    "    description=\"Logistic Regression classifier for prostate cancer detection task\",\n",
    "    n_classes=N_CLASSES,\n",
    "    torch_model=torch_model,\n",
    "    preprocessing=preprocessing,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Clipping\n",
    "\n",
    "To enable differentially private aggregation, client updates must satisfy a bounded sensitivity constraint. We therefore clip gradients prior to aggregation so that their â„“_2 norm does not exceed a prescribed threshold.\n",
    "\n",
    "For a given layer $\\ell$, let $g_\\ell$ denote its gradient and $C_\\ell$ the clipping bound. The clipped gradient is defined as:\n",
    "\n",
    "$$\n",
    "g_\\ell \\leftarrow g_\\ell \\cdot \\min\\left(1, \\frac{C_\\ell}{\\|g_\\ell\\|_2}\\right).\n",
    "$$\n",
    "\n",
    "The clipping threshold is **layer-wise and adaptive**. Specifically, for each layer:\n",
    "\n",
    "$$\n",
    "C_\\ell = \\alpha \\, \\|W_\\ell\\|_2,\n",
    "$$\n",
    "\n",
    "where $W_\\ell$ are the layer weights and $\\alpha$ is a fixed scaling coefficient. Thus, the clipping bound scales linearly with the norm of the corresponding layerâ€™s parameters.\n",
    "\n",
    "This formulation provides two key benefits:\n",
    "\n",
    "- **Layer-wise proportional scaling:** Layers with larger weight norms are allowed proportionally larger updates, preventing systematic over-clipping of high-magnitude layers.\n",
    "- **Improved privacyâ€“utility trade-off:** By bounding sensitivity in proportion to each layerâ€™s scale, the Gaussian noise calibrated to the global $(\\varepsilon, \\delta)$-DP budget is better aligned with the model geometry, reducing unnecessary degradation of convergence.\n",
    "\n",
    "In summary, gradients are norm-clipped per layer, with thresholds defined as a constant multiple of each layerâ€™s weight norm, enabling stable and efficient differentially private training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concretely, we set the base gradient clipping threshold to 0.1 and enable layer-wise adaptive clipping, which improves model accuracy while preserving comparable (Îµ, Î´)-differential privacy guarantees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADIENT_CLIPPING = 0.1\n",
    "ADAPTIVE_CLIPPING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of the gradient clipping on the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to tune the gradient clipping threshold to optimize the final federated learning performance.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- **High clipping threshold** â†’ increases the sensitivity of client updates, requiring more DP noise during aggregation.\n",
    "\n",
    "- **Low clipping threshold** â†’ excessively restricts updates, which can slow local training convergence and degrade utility.\n",
    "\n",
    "Selecting an appropriate value is therefore critical to achieving a good privacyâ€“utility trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the federated trainer `TITrainer` that specifies loss and optimizer and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "loss = TILoss(loss_func=nn.CrossEntropyLoss())\n",
    "\n",
    "optimizer = TIOptimizer(\n",
    "    optimizer_type=OptimizerType.SECURE_SGD,\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM\n",
    ")\n",
    "\n",
    "trainer = TITrainer(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    gradient_clipping=GRADIENT_CLIPPING,\n",
    "    adaptive_gradient_clipping=ADAPTIVE_CLIPPING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with a preliminary local training on your dataset\n",
    "\n",
    "Create the datasets for local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"split\"] == \"train\"].drop(columns=[\"split\"])\n",
    "val_df = df[df[\"split\"] == \"val\"].drop(columns=[\"split\"])\n",
    "\n",
    "train_dataset = CSVDataset(df = train_df)\n",
    "val_dataset = CSVDataset(df = val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the trainer to avoid modifications on the federated trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_trainer = TITrainer.unmarshal_binary(trainer.marshal_binary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for 3 epochs using the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_trainer.train(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    epochs=3,\n",
    "    eval_after_epoch=True,\n",
    "    logging_frequency=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy = round(local_trainer.history.get_curve(\"accuracy\")[-1][2], 4)\n",
    "print(\"Local accuracy:\", local_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Parameters for Federated Learning\n",
    "\n",
    "We perform 3 communication rounds, each consisting of 1 local training epoch per client before aggregation.\n",
    "\n",
    "Differential privacy is a popular definition of privacy. It requires that the output of a randomized algorithm does not change too much between two datasets that differ by one record.\n",
    "\n",
    "We enforce client-level differential privacy with parameters (Îµ, Î´), which bound the information that the aggregated model can reveal about any individual training sample contained in a clientâ€™s local dataset. \n",
    "\n",
    "More formally:\n",
    "\n",
    "- **Îµ (epsilon)** controls the privacy loss: smaller values provide stronger privacy guarantees but typically reduce model utility.\n",
    "- **Î´ (delta)** represents the probability of the privacy guarantee being violated and is chosen to be negligible relative to the dataset size.\n",
    "\n",
    "Differential privacy is achieved by clipping client updates to bound sensitivity and adding calibrated Gaussian noise during aggregation. This ensures that the contribution of any single data point remains statistically indistinguishable within the specified (Îµ, Î´) budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_epsilon = 1\n",
    "dp_delta = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = models.HybridFLGenericParams(\n",
    "    fl_rounds=3,\n",
    "    num_workers=2,\n",
    "    strategy = models.aggregation_strategy.AggregationStrategy.CONSTANT\n",
    ")\n",
    "\n",
    "ml_params = models.HybridFLMachineLearningParams(\n",
    "    local_epochs=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    momentum=MOMENTUM\n",
    ")\n",
    "\n",
    "dp_params = models.HybridFLDpParams(\n",
    "    delta=dp_delta,\n",
    "    gradient_clipping=GRADIENT_CLIPPING,\n",
    "    use_clipping_factor=ADAPTIVE_CLIPPING,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the computation (Federated Learning) on the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_fl = HybridFL(\n",
    "    project=project,\n",
    "    task_id = \"logreg\",\n",
    "    trainer=trainer,\n",
    "    params=params,\n",
    "    spec_params= ml_params,\n",
    "    dp_params=dp_params,\n",
    "    dp_epsilon=dp_epsilon\n",
    ")\n",
    "hybrid_fl.max_timeout = 300 * 60 * time.SECOND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clients authorize the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.request_authorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can get a quick summary of the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.display_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.display_datasources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training\n",
    "\n",
    "This will run a federated learning on the network of four instances (three contributing, and a coordinating root node).\n",
    "\n",
    "Note: you might experience the following error\n",
    "\n",
    "> `InternalError: error happened internally: unexpected error: please contact the instance's administrator`\n",
    "\n",
    "if that is the case, please call one of the organizers for assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_fl.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the result history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = project.fetch_results()[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_fl.display_results(results.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "federated_accuracy = round(json.loads(results.history.metrics[-1])[\"accuracy\"][-1][1], 4)\n",
    "print(\"Local accuracy:\", local_accuracy)\n",
    "print(\"Federated accuracy:\", federated_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
